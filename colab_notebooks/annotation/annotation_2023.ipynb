{"cells":[{"cell_type":"markdown","source":["# Create annotation files"],"metadata":{"id":"sdqykTCEADmT"}},{"cell_type":"markdown","metadata":{"id":"5957qeHf4Bg8"},"source":["Script to generate files needed for manual annotation. \n","\n","0) mount drive\n","\n","1) Run block #1.\n","\n","2) Change the sample name in block #2 and run. Will generate annotation files for all image blocks for that sample. Output is in /Annotation/ 2023/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23453,"status":"ok","timestamp":1680114857432,"user":{"displayName":"Fate Track","userId":"00899138229569203583"},"user_tz":240},"id":"Ppp1b-3D4lkT","outputId":"1597a14f-4940-4f4e-ac98-9d7e384f59eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install ipdb\n","import ipdb"],"metadata":{"id":"n9-So5VOu72N"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ceEh46vp7Ihn","executionInfo":{"status":"ok","timestamp":1680114864991,"user_tz":240,"elapsed":7562,"user":{"displayName":"Fate Track","userId":"00899138229569203583"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cca17368-cf1d-4cc2-cbb8-d9858080e847"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting dill\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dill\n","Successfully installed dill-0.3.6\n"]}],"source":["# 1) setup\n","#load packages\n","import pandas as pd\n","import numpy as np\n","from skimage import io,util, measure\n","import shutil,re,datetime\n","import os\n","import sys\n","!pip install dill\n","import dill\n","from scipy.spatial.distance import cdist\n","# !pip install ipdb\n","# import ipdb\n","\n","# load function for fatetrack objects\n","def load_object(filename):\n","   with open(filename, 'rb') as red:  # Overwrites any existing file.\n","       tmp = dill.load(red)\n","   return(tmp)\n","\n","\n","# function to reformat cell type names\n","def strip_list_format(celltype_list):\n","  if celltype_list == 'none':\n","    return 'none'\n","  if len(celltype_list) == 1:\n","    return celltype_list[0]\n","  elif len(celltype_list) == 2 and celltype_list[0] == '1_YFP' and celltype_list[1] == '2_CY5':\n","    return '1_YFP_2_CY5'\n","  else:\n","    return 'none'\n","\n","\n","def mCherryToDAPITranslation(mCherry_props, DAPI_props):\n","  \"\"\" Find the corresponding nuclear labels in the HCR Round 1 mCherry and DAPI images.\n","\n","  Parameters\n","  _________\n","  mCherry_props: DataFrame\n","    contains properties of the nuclei in the mCherry image (label and centroid)\n","  DAPI_props: DataFrame\n","    contains properties of the nuclei in the DAPI image (label and centroid), comes directly from self.HCR_measurements\n","\n","  Returns\n","  _______\n","  label_translation: DataFrame\n","    contains the nuclear label in the mCherry image and its corresponding label in the DAPI image\n","  \"\"\"\n","  mCherry = mCherry_props\n","  DAPI = DAPI_props\n","  mCherry_nucs = np.asarray(mCherry[['centroid-0', 'centroid-1']])  # get centroid positions for mCherry nuclei\n","  DAPI_nucs = np.asarray(DAPI[['nuc_Rd1_centroid-0', 'nuc_Rd1_centroid-1']])  # get centroid positions for DAPI nuclei\n","  centroid_dist = cdist(mCherry_nucs, DAPI_nucs)  # find the Euclidean distance between each mCherry nucleus and each DAPI nucleus\n","  closest_DAPI_nucleus = np.argmin(centroid_dist, axis = 1)  # index of each of the closest DAPI nuclei\n","  closest_DAPI_label = DAPI.iloc[closest_DAPI_nucleus][['Rd1_orig_label_DAPI']]  # gets the labels of each closest DAPI nucleus in the right order to merge back with the mCherry nuclei\n","  label_translation = np.concatenate([np.asarray(mCherry[['label']]), np.asarray(closest_DAPI_label)], axis = 1)  # concatenate mCherry labels with corresponding DAPI labels\n","  label_translation = np.delete(label_translation, np.nonzero(np.amin(centroid_dist, axis = 1) > 10), axis = 0)  # remove rows where distance between the nuclei > 10 px\n","  label_translation = pd.DataFrame(label_translation, columns = ['Rd1_orig_label', 'Rd1_orig_label_DAPI'])  # convert to dataframe\n","  label_translation.drop_duplicates(subset = 'Rd1_orig_label_DAPI', keep = False, inplace = True)\n","  return label_translation\n","\n","\n","# function to generate all needed files for annotation\n","def generateAnnotationFiles(ftoDir, sampleBase, block):\n","    # make the file\n","    sample = sampleBase + \"_2trailing_block\" + str(block) + \"of9\"\n","    fto = load_object(ftoDir + sample + '/' + sample + '.pkl')\n","    hcrs = fto.HCR_measurements\n","    hcrs_lp_meas = hcrs.filter(like = \"mean\").filter(like = \"lp\")\n","    hcrs_lp_meas = hcrs_lp_meas * 10000  # makes the number interpretable in MATLAB\n","    hcrs = pd.concat([hcrs[['Rd1_orig_label_DAPI', 'celltype', 'lp_Rd1_centroid-0', 'lp_Rd1_centroid-1']], hcrs_lp_meas.astype(int), hcrs.filter(like = \"mean\").filter(like = \"nuc\").astype(int)], axis = 1)\n","    hcrs['annotation'] = hcrs['celltype'].apply(strip_list_format)\n","\n","    # get all HCR mCherry nuclei\n","    # HCR_Rd1_mCherrymask_props = pd.DataFrame(measure.regionprops_table(fto.HCR_Rd1_mCherry_mask,intensity_image= fto.HCR_Rd1_mCherry_image, \n","                                                                        # properties=['label','bbox','centroid','area','mean_intensity']))\n","    HCR_Rd1_mCherry_labels_centroids = pd.concat([fto.HCR_Rd1_mCherrymask_props[['label']], fto.HCR_Rd1_mCherrymask_props[['centroid-0', 'centroid-1']].astype(int)], axis=1)\n","    HCR_Rd1_mCherry_labels_centroids.rename(columns={\"label\" : \"Rd1_orig_label\"}, inplace=True)\n","\n","    # translation between mCherry and DAPI nuclei\n","    # mCherry_DAPI_translation = mCherryToDAPITranslation(HCR_Rd1_mCherrymask_props, fto.HCR_measurements)\n","    \n","    # do a left join to get all mCherry nuclei and their correspondign DAPI label, and then all the DAPI properties from \"hcrs\"\n","    measDF = HCR_Rd1_mCherry_labels_centroids.merge(fto.mCherry_DAPI_translation, on=\"Rd1_orig_label\")\n","    measDF = measDF.merge(hcrs, on=\"Rd1_orig_label_DAPI\")\n","\n","    measDF = measDF.rename(columns = {'Rd1_orig_label_DAPI' : 'pointID', 'lp_Rd1_centroid-0' : 'yCoord', 'lp_Rd1_centroid-1' : 'xCoord'})\n","    measDF.drop(columns=['celltype'], inplace=True)\n","    # make a directory to save the files to\n","    path = '/content/drive/MyDrive/FateTrack_Main/Annotation/2023/' + sampleBase + '/' + sample\n","    if not os.path.isdir(path):\n","      os.makedirs(path)\n","    # save the annotation file and the aligned tifs to the directory\n","    measDF.to_csv(path + \"/\" + sample + \"_annotations.csv\", index = False)\n","    images1 = fto.HCR_Rd1_images\n","    images2 = fto.HCR_Rd2_images\n","    io.imsave(path + \"/mask.tif\", util.img_as_uint(fto.HCR_Rd1_DAPI_mask>0))\n","    io.imsave(path + \"/1CY5.tif\", images1[np.where(fto.HCR_channelList=='CY5')[0][0]])\n","    io.imsave(path + \"/1CY3.tif\", images1[np.where(fto.HCR_channelList=='CY3')[0][0]])\n","    io.imsave(path + \"/1YFP.tif\", images1[np.where(fto.HCR_channelList=='YFP')[0][0]])\n","    io.imsave(path + \"/1DAPI.tif\", images1[np.where(fto.HCR_channelList=='DAPI')[0][0]])\n","    io.imsave(path + \"/1A594.tif\", images1[np.where(fto.HCR_channelList=='A594')[0][0]])\n","    io.imsave(path + \"/2CY5.tif\", images2[np.where(fto.HCR_channelList=='CY5')[0][0]])\n","    io.imsave(path + \"/2CY3.tif\", images2[np.where(fto.HCR_channelList=='CY3')[0][0]])\n","    io.imsave(path + \"/2YFP.tif\", images2[np.where(fto.HCR_channelList=='YFP')[0][0]])\n","    io.imsave(path + \"/2DAPI.tif\", images2[np.where(fto.HCR_channelList=='DAPI')[0][0]])\n","    io.imsave(path + \"/2A594.tif\", images2[np.where(fto.HCR_channelList=='A594')[0][0]])"]},{"cell_type":"code","source":["sampleBase = \"507_D3_1_w1\"\n","block = 0\n","ftoDir = '/content/drive/MyDrive/FateTrack_Main/test/1028/'\n","sample = sampleBase + \"_2trailing_block\" + str(block) + \"of9\"\n","fto = load_object(ftoDir + sample + '/' + sample + '.pkl')\n","hcrs = fto.HCR_measurements\n","# hcrs_lp_meas = hcrs.filter(like = \"mean\").filter(like = \"lp\")\n","# hcrs_lp_meas = hcrs_lp_meas * 10000  # makes the number interpretable in MATLAB\n","# hcrs = pd.concat([hcrs[['Rd1_orig_label_DAPI', 'celltype']], hcrs_lp_meas.astype(int), hcrs.filter(like = \"mean\").filter(like = \"nuc\").astype(int)], axis = 1)\n","\n","# # get all HCR mCherry nuclei\n","# HCR_Rd1_mCherrymask_props = pd.DataFrame(measure.regionprops_table(fto.HCR_Rd1_mCherry_mask,intensity_image= fto.HCR_Rd1_mCherry_image, \n","#                                                                     properties=['label','bbox','centroid','area','mean_intensity']))\n","# HCR_Rd1_mCherry_labels_centroids = pd.concat([HCR_Rd1_mCherrymask_props[['label']], HCR_Rd1_mCherrymask_props[['centroid-0', 'centroid-1']].astype(int)], axis = 1)\n","# HCR_Rd1_mCherry_labels_centroids.rename(columns={\"label\" : \"Rd1_orig_label\"}, inplace=True)\n","\n","# # translation between mCherry and DAPI nuclei\n","# mCherry_DAPI_translation = mCherryToDAPITranslation(HCR_Rd1_mCherrymask_props, fto.HCR_measurements)\n"],"metadata":{"id":"Q10HOqW3MHPE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j_bfZjDoCE_H"},"outputs":[],"source":["# 2) set sample and run functions\n","ftoDir = '/content/drive/MyDrive/FateTrack_Main/test/1028/'\n","sampleBase = \"507_D3_1_w1\"\n","for block in range(6,7):\n","  generateAnnotationFiles(ftoDir, sampleBase, block)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-pvU8I3Krjyq"},"outputs":[],"source":["# 2) set sample and run functions\n","ftoDir = '/content/drive/MyDrive/FateTrack_Main/test/1028/'\n","samples = [(\"507_D3_1_w1\", 0), (\"507_D3_1_w2\", 3), (\"516_D4_2_w1\", 4), (\"621_D2_1_w2\", 7)]\n","for sampleBase, block in samples:\n","  generateAnnotationFiles(ftoDir, sampleBase, block)"]},{"cell_type":"markdown","source":["# Merge annotations back into FateTrack object"],"metadata":{"id":"RYw3HRODggTx"}},{"cell_type":"code","source":["def save_object(obj, filename):\n","    \"\"\"Save a FateTrack object to a .pkl file.\n","\n","    Parameters\n","    __________\n","    obj: FateTrack object.\n","      The filename for the .pkl object.\n","    filename: str\n","      The filename for the .pkl object.\n","    \"\"\"\n","    with open(filename, 'wb') as output:  # Overwrites any existing file.\n","        dill.dump(obj, output)\n","\n","\n","def merge_annotations(ftoDir, sampleBase, block):\n","  # open FateTrack object\n","  sample = sampleBase + \"_2trailing_block\" + str(block) + \"of9\"\n","  fto = load_object(ftoDir + sample + '/' + sample + '.pkl')\n","  # load annotation file\n","  annotations = pd.read_csv('/content/drive/MyDrive/FateTrack_Main/Annotation/2023/' + sampleBase + \"/\" + sample + \"/\" + sample + \"_annotations.csv\")\n","\n","  hcrs = fto.HCR_measurements\n","  print(len(hcrs))\n","  annotations = annotations[[\"pointID\", \"annotation\"]]\n","  hcrs = hcrs.merge(annotations, left_on = \"Rd1_orig_label_DAPI\", right_on = \"pointID\")\n","  hcrs = hcrs.drop(columns =['celltype'])\n","  hcrs = hcrs.rename(columns = {'annotation' : 'celltype'})\n","  fto.HCR_measurements = hcrs\n","  save_object(fto, ftoDir + sample + '/' + sample + '.pkl')\n","  \n"],"metadata":{"id":"5sif7TMbglRV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ftoDir = '/content/drive/MyDrive/FateTrack_Main/test/1028/'\n","sampleBase = \"507_D3_1_w1\"\n","block = 6\n","merge_annotations(ftoDir, sampleBase, block)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yqEFYZKAo69j","executionInfo":{"status":"ok","timestamp":1680116016889,"user_tz":240,"elapsed":12197,"user":{"displayName":"Fate Track","userId":"00899138229569203583"}},"outputId":"4aed4535-601c-44d2-f022-522ffdc9f70b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5148\n"]}]},{"cell_type":"code","source":["# combine split annotations into single annotation file\n","# for tiled connection files\n","sample = sampleBase + \"_2trailing_block\" + str(block) + \"of9\"\n","annotations_all = pd.DataFrame()\n","for i in range(9):\n","  tile_annotations = pd.read_csv('/content/drive/MyDrive/FateTrack_Main/Annotation/2023/' + sampleBase + \"/\" + sample + \"/tile\" + str(i) + \".csv\")\n","  annotations_all = pd.concat([annotations_all, tile_annotations], axis = 0)\n","annotations_all = annotations_all.reset_index(drop = True)\n","annotations_all.to_csv('/content/drive/MyDrive/FateTrack_Main/Annotation/2023/' + sampleBase + \"/\" + sample + \"/\" + sample + \"_annotations.csv\")\n"],"metadata":{"id":"-8-Ry9fBpIZt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# split up annotation file"],"metadata":{"id":"H_L2sE7zKN1U"}},{"cell_type":"code","source":["# read in annotation\n","annotation = pd.read_csv('/content/drive/MyDrive/FateTrack_Main/Annotation/2023/507_D3_1_w1/507_D3_1_w1_2trailing_block6of9/507_D3_1_w1_2trailing_block6of9_annotations.csv')\n","cutoffs = [-1, 1032, 2066, 3100]\n","tiles = []\n","for x in range(1, 4):\n","  for y in range(1,4):\n","    tiles = tiles + [annotation.query('xCoord > @cutoffs[@x - 1] & xCoord <= @cutoffs[@x] & yCoord > @cutoffs[@y - 1] & yCoord <= @cutoffs[@y]')]\n","\n","for i, tile in enumerate(tiles):\n","  tile.to_csv('/content/drive/MyDrive/FateTrack_Main/Annotation/2023/507_D3_1_w1/507_D3_1_w1_2trailing_block6of9/tile' + str(i) + '.csv', index = False)"],"metadata":{"id":"dDr1gxGiKQEY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# not this one"],"metadata":{"id":"34M-GfjIALI_"}},{"cell_type":"markdown","metadata":{"id":"u63cQ25qALI_"},"source":["Script to generate files needed for manual annotation. \n","\n","0) mount drive\n","\n","1) Run block #1.\n","\n","2) Change the sample name in block #2 and run. Will generate annotation files for all image blocks for that sample. Output is in /Annotation/ 2023/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20628,"status":"ok","timestamp":1675457143628,"user":{"displayName":"Fate Track","userId":"00899138229569203583"},"user_tz":300},"outputId":"8970be4f-93a3-4e8e-9763-b5ba791caf39","id":"PzcsQI5aALJF"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSCGeB7kALJG"},"outputs":[],"source":["# 1) setup\n","#load packages\n","import pandas as pd\n","import numpy as np\n","from skimage import io,util, measure\n","import shutil,re,datetime\n","import os\n","import sys\n","import dill\n","!pip install ipdb\n","import ipdb\n","\n","# load function for fatetrack objects\n","def load_object(filename):\n","   with open(filename, 'rb') as red:  # Overwrites any existing file.\n","       tmp = dill.load(red)\n","   return(tmp)\n","\n","\n","# function to generate all needed files for annotation\n","def generateAnnotationFiles(ftoDir, sampleBase, block):\n","    # make the file\n","    sample = sampleBase + \"_2trailing_block\" + str(block) + \"of9\"\n","    fto = load_object(ftoDir + sample + '/' + sample + '.pkl')\n","    hcrs = fto.HCR_measurements\n","    hcrs_lp_meas = hcrs.filter(like = \"mean\").filter(like = \"lp\")\n","    hcrs_lp_meas = hcrs_lp_meas * 10000  # makes the number interpretable in MATLAB\n","    hcrs = pd.concat([hcrs[['Rd1_orig_label_DAPI', 'celltype']], hcrs[['lp_Rd1_centroid-0', 'lp_Rd1_centroid-1']].astype(int), hcrs_lp_meas.astype(int), hcrs.filter(like = \"mean\").filter(like = \"nuc\").astype(int)], axis = 1)\n","    masterDF_subset = fto.masterDF.drop(columns=[\"Unnamed: 0\"]).drop_duplicates()[['Rd1_orig_label', 'Rd1_orig_label_DAPI']]  # all the drop steps deal with an underlying duplication error that has been addressed in the FateTrack processing pipeline now\n","    measDF = masterDF_subset.merge(hcrs, 'left', on='Rd1_orig_label_DAPI')\n","    measDF = measDF.rename(columns = {'Rd1_orig_label_DAPI' : 'pointID', 'lp_Rd1_centroid-0' : 'yCoord', 'lp_Rd1_centroid-1' : 'xCoord'})\n","    measDF['annotation'] = measDF['celltype'].apply(strip_list_format)\n","    measDF.drop(columns=['celltype', 'Rd1_orig_label'], inplace=True)\n","    # make a directory to save the files to\n","    path = '/content/drive/MyDrive/FateTrack_Main/Annotation/2023/' + sampleBase + '/' + sample\n","    if not os.path.isdir(path):\n","      os.makedirs(path)\n","    # save the annotation file and the aligned tifs to the directory\n","    measDF.to_csv(path + \"/\" + sample + \"_annotations.csv\", index = False)\n","    images1 = fto.HCR_Rd1_images\n","    images2 = fto.HCR_Rd2_images\n","    io.imsave(path + \"/mask.tif\", util.img_as_uint(fto.HCR_Rd1_DAPI_mask>0))\n","    # io.imsave(path + \"/cyto_mask.tif\", util.img_as_uint(fto.HCR_Rd1_cyto_mask>0))\n","    io.imsave(path + \"/1CY5.tif\", images1[np.where(fto.HCR_channelList=='CY5')[0][0]])\n","    io.imsave(path + \"/1CY3.tif\", images1[np.where(fto.HCR_channelList=='CY3')[0][0]])\n","    io.imsave(path + \"/1YFP.tif\", images1[np.where(fto.HCR_channelList=='YFP')[0][0]])\n","    io.imsave(path + \"/1DAPI.tif\", images1[np.where(fto.HCR_channelList=='DAPI')[0][0]])\n","    io.imsave(path + \"/1A594.tif\", images1[np.where(fto.HCR_channelList=='A594')[0][0]])\n","    io.imsave(path + \"/2CY5.tif\", images2[np.where(fto.HCR_channelList=='CY5')[0][0]])\n","    io.imsave(path + \"/2CY3.tif\", images2[np.where(fto.HCR_channelList=='CY3')[0][0]])\n","    io.imsave(path + \"/2YFP.tif\", images2[np.where(fto.HCR_channelList=='YFP')[0][0]])\n","    io.imsave(path + \"/2DAPI.tif\", images2[np.where(fto.HCR_channelList=='DAPI')[0][0]])\n","    io.imsave(path + \"/2A594.tif\", images2[np.where(fto.HCR_channelList=='A594')[0][0]])"]},{"cell_type":"code","source":["sample = '507_D3_1_w1'\n","block = 0\n","sample = sampleBase + \"_2trailing_block\" + str(block) + \"of9\"\n","fto = load_object(ftoDir + sample + '/' + sample + '.pkl')\n","TL_last_m"],"metadata":{"id":"6ywlkHvFB4ei"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"10wUfJ2zZ_2KUcZCqyv-AG7hYO29zNL0F","timestamp":1674070868678}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}